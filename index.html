<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Dexter Neo Yuan Rong (梁员荣)</title>

    <meta name="author" content="Dexter Neo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Dexter Neo (梁员荣)
                </p>
                <p>I am a PhD student at the School of Computing Science at the National University of Singapore (NUS), advised by <a href="https://www.nus.edu.sg/about/management/chen-tsuhan"> Professor Tsuhan Chen </a> and co-advisor <a href="https://vintage.winklerbros.net/index.html"> A.P Stefan Winkler </a>. I also served as a teaching assistant for <a href="https://nusmods.com/courses/CS4243/computer-vision-and-pattern-recognition"> CS4243 </a>
                </p>
                <p>
                Prior to my PhD, I obtained my Master's in Computer Science (AI) from NUS, and my Bachelor's in Engineering from University of Glasgow (First Class Honours).
                </p>
                <p style="text-align:center">
                  <a href="mailto:dexterdley94@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://github.com/dexterdley"> GitHub</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=XfQNdF8AAAAJ"> Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/dexter-neo-762190175"> LinkedIn </a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/photo1709952056.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/photo1709952056.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research Publications</h2>
                <p>
                My research mainly focuses on <i> Deep Neural Network Calibration </i>, <i> Uncertainty Quantification </i>, <i> Safe, Robust and Trustworty AI </i> for computer vision and natural language tasks. I also dabble around with <i> Facial Expression Recognition </i> and <i> Deep Reinforcement Learning </i>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/maxent_ood_figure_main.png" alt="Dexter" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2310.17159" id="MCG_journal">
                  <span class="papertitle">MaxEnt Loss: Constrained Maximum Entropy for Network Calibration under Out-of-Distribution Shift</span>
                </a>
                <br>
                <b> Dexter Neo </b>, Stefan Winkler, Tsuhan Chen
                <br>
                <em>AAAI</em>, 2024 [Vancouver, Canada] [<span class="highlight">Oral Presentation*</span>]
                <br>
                <a href="https://arxiv.org/abs/2310.17159">arXiv</a> /
                <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
                <a href="https://github.com/dexterdley/MaxEnt-Loss">code</a>
                <p></p>
                <p>We present a new loss function that addresses the out-of-distribution (OOD) calibration problem. While many objective functions have been proposed to effectively calibrate models in-distribution, our findings show that they do not always fare well OOD. Based on the Principle of Maximum Entropy, we incorporate helpful statistical constraints observed during training, delivering better model calibration without sacrificing accuracy. We provide theoretical analysis and show empirically that our method works well in practice, achieving state-of-the-art calibration on both synthetic and real-world benchmarks.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/CS6208_project_celeba_ood.png" alt="Dexter" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">MaxEnt Loss: Calibrating Graph Neural Networks under Out-of-Distribution Shift (Student Abstract)</span>
                <br>
                <b> Dexter Neo </b>
                <br>
                <em>AAAI</em>, 2024 [Vancouver, Canada] [Poster]
                <br>
                <a href="https://github.com/dexterdley/CS6208">code</a>
                <p></p>
                <p>In our abstract, we show that MaxEnt Loss can be to improve the calibration of Graph Neural Networks.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/GMM_example.png" alt="Dexter" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://openaccess.thecvf.com/content/CVPR2023W/ABAW/html/Neo_Large-Scale_Facial_Expression_Recognition_Using_Dual-Domain_Affect_Fusion_for_Noisy_CVPRW_2023_paper.html" id="MCG_journal">
                  <span class="papertitle">MaxEnt Loss: Constrained Maximum Entropy for Network Calibration under Out-of-Distribution Shift</span>
                </a>
                <br>
                <b> Dexter Neo </b>, Stefan Winkler, Tsuhan Chen
                <br>
                <em>CVPRW</em>, 2023 [Vancouver, Canada] [Oral Presentation]
                <br> 
                <a href="https://openaccess.thecvf.com/content/CVPR2023W/ABAW/html/Neo_Large-Scale_Facial_Expression_Recognition_Using_Dual-Domain_Affect_Fusion_for_Noisy_CVPRW_2023_paper.html">paper</a>
                <a href="https://https://github.com/dexterdley/FER_C">code</a>
                <p></p>
                <p>In this paper, we propose an approach for dual-domain affect fusion which investigates the relationships between discrete emotion classes and their continuous representations. In order to address the underlying uncertainty of the labels, we formulate a set of mixed labels via a dual-domain label fusion module to exploit these intrinsic relationships..</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/sample_sadness.PNG" alt="Dexter" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2103.02854" id="MCG_journal">
                  <span class="papertitle">Morphset: Augmenting Categorical Emotion Datasets
                    with Dimensional Affect Labels Using Face Morphing</span>
                </a>
                <br>
                Vassilios Vonikakis, <b> Dexter Neo </b>, Stefan Winkler
                <br>
                <em>ICIP</em>, 2021 [Anchorage Alaska, USA] [Poster]
                <br>
                <a href="https://arxiv.org/abs/2103.02854">arXiv</a> /
                <a href="https://github.com/dexterdley/MorphSet">code</a>
                <p></p>
                <p>We propose a method to generate synthetic images from existing categorical emotion datasets using
                  face morphing as well as dimensional labels in the circumplex
                  space with full control over the resulting sample distribution.</p>
              </td>
            </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Preprints</h2>
                <p>
                These include primers, courseworks, side projects and ongoing research work..
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/peacock_figure1.png" alt="Dexter" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <span class="papertitle">Peacock: Combining Improvements in Deep Neural Network Calibration</span>
                <br>
                <b> Dexter Neo </b>, Tsuhan Chen
                <br>
                <em>arXiv Preprint coming soon!
                <br>
                <p></p>
                <p>The calibration community has made several independent advancements towards safe, reliable and trustworthy neural networks. However, it remains unclear which algorithms are complementary and can be integrated to fruition. This paper studies a total of seven different calibration algorithms and empirically examines their combination. Our experiments show that combining multiple state-of-the-art methods can further improve calibration performance on both in and out-of-distribution benchmarks. We also provide detailed results in our ablation study investigating the contributions of each component..</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/soft_ood_figure1.png" alt="Dexter" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2312.11542" id="MCG_journal">
                  <span class="papertitle">FER-C: Benchmarking Out-of-Distribution Soft Calibration for Facial Expression Recognition</span>
                </a>
                <br>
                <b> Dexter Neo </b>, Tsuhan Chen
                <br>
                <em>arXiv Preprint
                <br>
                <a href="https://arxiv.org/abs/2312.11542">arXiv</a> /
                <a href="https://https://github.com/dexterdley/FER_C">code</a>
                <p></p>
                <p>We present a soft benchmark for calibrating facial expression recognition (FER). While prior works have focused on identifying affective states, we find that FER models are uncalibrated. This is particularly true when out-of-distribution (OOD) shifts further exacerbate the ambiguity of facial expressions. While most OOD benchmarks provide hard labels, we argue that the ground-truth labels for evaluating FER models should be soft in order to better reflect the ambiguity behind facial behaviours. Our framework proposes soft labels that closely approximates the average information loss based on different types of OOD shifts.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/noisy_atari.png" alt="Dexter" width="160" style="border-style: none">
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2310.17173" id="MCG_journal">
                  <span class="papertitle">DSAC-C: Constrained Maximum Entropy for Robust Discrete Soft-Actor Critic</span>
                </a>
                <br>
                <b> Dexter Neo </b>, Tsuhan Chen
                <br>
                <em>arXiv Preprint
                <br>
                <a href="https://arxiv.org/abs/2310.17173">arXiv</a> 
                <p></p>
                <p>We present a novel extension to the family of Soft Actor-Critic (SAC) algorithms. We argue that based on the Maximum Entropy Principle, discrete SAC can be further improved via additional statistical constraints derived from a surrogate critic policy. Furthermore, our findings suggests that these constraints provide an added robustness against potential domain shifts, which are essential for safe deployment of reinforcement learning agents in the real-world. We provide theoretical analysis and show empirical results on low data regimes for both in-distribution and out-of-distribution variants of Atari 2600 games.</p>
              </td>
            </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Awards</h2>
                <p>[<b>2023</b>] Research Incentive Award, One-time award of $2500 from the Department of Computer Science. (NUS, Singapore)
                </p>
                <p>[<b>2020</b>] National Graduate Research Scholarship 2020. (NUS, Singapore)
                </p>
                <p>[<b>2019</b>] 3rd Place, Visual SLAM Competition, IEEE International Symposium of Mixed and Augmented Reality 2019. (Beijing, China)
                </p>
                <p>[<b>2019</b>] Engineering Excellence List, Head of School of Engineering. (University of Glasgow, UK)
                </p>
                <p>[<b>2018</b>] Engineering Excellence List, Head of School of Engineering. (University of Glasgow, UK)
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  This website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a> is from Jon Barron, credits to the author.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
